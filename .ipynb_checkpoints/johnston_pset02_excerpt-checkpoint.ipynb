{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ebe3c8a",
   "metadata": {},
   "source": [
    "# Stat 507, PSet 2 Excerpt for PSet6\n",
    "**Heather Johnston**\n",
    "\n",
    "*Original PSet2 completion: October 1, 2021*\n",
    "\n",
    "*PSet6 date: November 12, 2021*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e05572ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# The following may be necessary to download sas files from CDC website\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ee11dd",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2efe95f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Part a:\n",
    "\n",
    "# Set which vars and cohorts to extract\n",
    "relevant_vars = [\"SEQN\", \"RIDAGEYR\", \"RIDRETH3\", \"DMDEDUC2\", \n",
    "                 \"DMDMARTL\", \"RIDSTATR\", \"SDMVPSU\", \"SDMVSTRA\", \n",
    "                 \"WTMEC2YR\", \"WTINT2YR\"]\n",
    "cohort_keys = [\"2011-2012/DEMO_G\", \"2013-2014/DEMO_H\", \n",
    "               \"2015-2016/DEMO_I\", \"2017-2018/DEMO_J\"]\n",
    "\n",
    "# Gather data from internet\n",
    "url_part_a = \"https://wwwn.cdc.gov/Nchs/Nhanes/\"\n",
    "url_part_c = \".XPT\"\n",
    "all_data = pd.DataFrame(columns=relevant_vars + [\"cohort\"])\n",
    "for years in cohort_keys:\n",
    "    url = url_part_a + years + url_part_c\n",
    "    df = pd.read_sas(url)\n",
    "    df = df.loc[:, relevant_vars]\n",
    "    df[\"cohort\"] = str(years)\n",
    "    all_data = pd.concat([all_data, df])\n",
    "    \n",
    "# Change names and types\n",
    "new_names = {\"SEQN\":\"respondent_id\",\n",
    "            \"RIDAGEYR\":\"age\",\n",
    "            \"RIDRETH3\":\"race\",\n",
    "            \"DMDEDUC2\":\"educ_level\",\n",
    "            \"DMDMARTL\":\"marital_status\",\n",
    "            \"RIDSTATR\":\"status\",\n",
    "            \"SDMVPSU\":\"psu\",\n",
    "            \"SDMVSTRA\":\"stratum\",\n",
    "            \"WTMEC2YR\":\"weight_exam\",\n",
    "            \"WTINT2YR\":\"weight_interview\"}\n",
    "new_types = {\"respondent_id\":str,\n",
    "            \"age\":int,\n",
    "            \"weight_exam\":float,\n",
    "            \"weight_interview\":float}\n",
    "all_data.rename(columns=new_names, inplace=True)\n",
    "all_data = all_data.astype(dtype=new_types)\n",
    "\n",
    "# Replace categorical data\n",
    "race_dictionary = {1: 'Mexican American', \n",
    "                   2: 'Other Hispanic',\n",
    "                   3: 'Non-Hispanic White',\n",
    "                   4: 'Non-Hispanic Black',\n",
    "                   6: 'Non-Hispanic Asian',\n",
    "                   7: 'Other Race / Multiracial'}\n",
    "all_data['race'] = pd.Categorical(all_data['race'].replace(race_dictionary))\n",
    "educ_dictionary = {1: 'Less than 9th grade',\n",
    "                  2: '9-11th grade',\n",
    "                  3: 'High school graduate / GED',\n",
    "                  4: 'Some college or AA degree',\n",
    "                  5: 'College graduate or above',\n",
    "                  7: 'Refused',\n",
    "                  9: 'Don\\'t know'}\n",
    "all_data['educ_level'] = pd.Categorical(\n",
    "    all_data['educ_level'].replace(educ_dictionary))\n",
    "marital_dictionary = {1: 'Married',\n",
    "                     2: 'Widowed',\n",
    "                     3: 'Divorced',\n",
    "                     4: 'Separated',\n",
    "                     5: 'Never married',\n",
    "                     6: 'Living with partner',\n",
    "                     77: 'Refused',\n",
    "                     99: 'Don\\'t Know'}\n",
    "all_data['marital_status'] = pd.Categorical(\n",
    "    all_data['marital_status'].replace(marital_dictionary))\n",
    "status_dictionary = {1: 'Interviewed only',\n",
    "                    2: 'Interviewed and examined'}\n",
    "all_data['status'] = pd.Categorical(\n",
    "    all_data['status'].replace(status_dictionary))\n",
    "\n",
    "# Write to pickle\n",
    "all_data.to_pickle(\"nhanes_demographic.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93a4debe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pandas/io/sas/sas_xport.py:475: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x] = v\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>OHDDESTS</th>\n",
       "      <th>OHX01TC</th>\n",
       "      <th>OHX02TC</th>\n",
       "      <th>OHX03TC</th>\n",
       "      <th>OHX04TC</th>\n",
       "      <th>OHX05TC</th>\n",
       "      <th>OHX06TC</th>\n",
       "      <th>OHX07TC</th>\n",
       "      <th>OHX08TC</th>\n",
       "      <th>...</th>\n",
       "      <th>OHX23CTC</th>\n",
       "      <th>OHX24CTC</th>\n",
       "      <th>OHX25CTC</th>\n",
       "      <th>OHX26CTC</th>\n",
       "      <th>OHX27CTC</th>\n",
       "      <th>OHX28CTC</th>\n",
       "      <th>OHX29CTC</th>\n",
       "      <th>OHX30CTC</th>\n",
       "      <th>OHX31CTC</th>\n",
       "      <th>cohort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62161.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'Z'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2011-2012/OHXDEN_G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62162.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'D'</td>\n",
       "      <td>b'D'</td>\n",
       "      <td>b'D'</td>\n",
       "      <td>b'D'</td>\n",
       "      <td>b'D'</td>\n",
       "      <td>b'D'</td>\n",
       "      <td>b'D'</td>\n",
       "      <td>b'U'</td>\n",
       "      <td>b'U'</td>\n",
       "      <td>2011-2012/OHXDEN_G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62163.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'Y'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2011-2012/OHXDEN_G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62164.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'Z'</td>\n",
       "      <td>b'Z'</td>\n",
       "      <td>2011-2012/OHXDEN_G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62165.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2011-2012/OHXDEN_G</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SEQN  OHDDESTS  OHX01TC  OHX02TC  OHX03TC  OHX04TC  OHX05TC  OHX06TC  \\\n",
       "0  62161.0       1.0      4.0      2.0      2.0      2.0      2.0      2.0   \n",
       "1  62162.0       1.0      4.0      4.0      4.0      1.0      1.0      1.0   \n",
       "2  62163.0       1.0      4.0      2.0      2.0      2.0      2.0      2.0   \n",
       "3  62164.0       1.0      4.0      2.0      2.0      2.0      2.0      2.0   \n",
       "4  62165.0       1.0      4.0      2.0      2.0      2.0      2.0      2.0   \n",
       "\n",
       "   OHX07TC  OHX08TC  ...  OHX23CTC  OHX24CTC  OHX25CTC  OHX26CTC  OHX27CTC  \\\n",
       "0      2.0      2.0  ...      b'S'      b'S'      b'S'      b'S'      b'S'   \n",
       "1      1.0      1.0  ...      b'D'      b'D'      b'D'      b'D'      b'D'   \n",
       "2      2.0      2.0  ...      b'S'      b'S'      b'S'      b'S'      b'S'   \n",
       "3      2.0      2.0  ...      b'S'      b'S'      b'S'      b'S'      b'S'   \n",
       "4      2.0      2.0  ...      b'S'      b'S'      b'S'      b'S'      b'S'   \n",
       "\n",
       "   OHX28CTC  OHX29CTC  OHX30CTC  OHX31CTC              cohort  \n",
       "0      b'S'      b'S'      b'Z'      b'S'  2011-2012/OHXDEN_G  \n",
       "1      b'D'      b'D'      b'U'      b'U'  2011-2012/OHXDEN_G  \n",
       "2      b'S'      b'S'      b'Y'      b'S'  2011-2012/OHXDEN_G  \n",
       "3      b'S'      b'S'      b'Z'      b'Z'  2011-2012/OHXDEN_G  \n",
       "4      b'S'      b'S'      b'S'      b'S'  2011-2012/OHXDEN_G  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Part b\n",
    "\n",
    "# Define relevant variables\n",
    "relevant_teeth_vars = [\"SEQN\", \"OHDDESTS\"]\n",
    "tooth_counts = [\"OHX\" + f\"{x:02}\" + \"TC\" \n",
    "                for x in range(1, 33)]\n",
    "cavity_counts = [\"OHX\" + f\"{x:02}\" + \"CTC\" \n",
    "                for x in range(2, 32)\n",
    "                if x != 16 and x != 17]\n",
    "relevant_teeth_vars = relevant_teeth_vars + tooth_counts + cavity_counts\n",
    "cohort_keys = [\"2011-2012/OHXDEN_G\", \"2013-2014/OHXDEN_H\", \n",
    "               \"2015-2016/OHXDEN_I\", \"2017-2018/OHXDEN_J\"]\n",
    "\n",
    "# Download data from internet\n",
    "url_part_a = \"https://wwwn.cdc.gov/Nchs/Nhanes/\"\n",
    "url_part_c = \".XPT\"\n",
    "teeth_data = pd.DataFrame(columns=relevant_teeth_vars + [\"cohort\"])\n",
    "for years in cohort_keys:\n",
    "    url = url_part_a + years + url_part_c\n",
    "    df = pd.read_sas(url)\n",
    "    df = df.loc[:, relevant_teeth_vars]\n",
    "    df[\"cohort\"] = str(years)\n",
    "    teeth_data = pd.concat([teeth_data, df])\n",
    "    \n",
    "teeth_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f41dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = {\"SEQN\":\"respondent_id\",\n",
    "            \"OHDDESTS\":\"dentition_status\"}\n",
    "tooth_count_new_names = [\"count_\" + f\"{x:02}\" for x in range(1, 33)]\n",
    "cavity_new_names = [\"cavities_\" f\"{x:02}\"\n",
    "                for x in range(2, 32)\n",
    "                if x != 16 and x != 17]\n",
    "for i, j in zip(tooth_counts + cavity_counts, \n",
    "                tooth_count_new_names + cavity_new_names):\n",
    "    new_names[i] = j\n",
    "\n",
    "teeth_data.rename(columns=new_names, inplace=True)\n",
    "\n",
    "dentition_dictionary = {1: 'Complete',\n",
    "                       2: 'Partial',\n",
    "                       3: 'Not done'}\n",
    "teeth_data['dentition_status'] = pd.Categorical(\n",
    "    teeth_data['dentition_status'].replace(dentition_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40e73435",
   "metadata": {},
   "outputs": [],
   "source": [
    "teeth_data.to_pickle(\"nhanes_teeth.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d11e879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39156, 11)\n",
      "(35909, 63)\n"
     ]
    }
   ],
   "source": [
    "# Part c\n",
    "print(all_data.shape)\n",
    "print(teeth_data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
