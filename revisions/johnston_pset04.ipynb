{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cef862b7",
   "metadata": {},
   "source": [
    "# Heather Johnston\n",
    "### Stats 507, Problem Set 4\n",
    "### Fall 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7b3ba19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from scipy.stats import norm, beta, chisquare, ttest_ind\n",
    "from IPython.core.display import display, HTML\n",
    "# Note to self: figure out matplotlib import conflict\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1f6421",
   "metadata": {},
   "source": [
    "# Question 0: Topic in Pandas\n",
    "\n",
    "## Stack and Unstack\n",
    "* Stack and Unstack are similar to \"melt\" and \"pivot\" methods for transforming data\n",
    "* R users may be familiar with \"pivot_wider\" and \"pivot_longer\" (formerly \"spread\" and \"gather\")\n",
    "* Stack transforms column names to new index and values to column\n",
    "\n",
    "## Example: Stack\n",
    "* Consider the `example` DataFrame below to be measurements of some value taken on different days at different times.\n",
    "* It would be natural to want these to be \"gathered\" into long format, which we can do using `stack`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e06e06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           morning  afternoon\n",
      "day                          \n",
      "Monday           4          8\n",
      "Wednesday        5          9\n",
      "Friday           6          0\n",
      "day                 \n",
      "Monday     morning      4\n",
      "           afternoon    8\n",
      "Wednesday  morning      5\n",
      "           afternoon    9\n",
      "Friday     morning      6\n",
      "           afternoon    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "example = pd.DataFrame({\"day\":[\"Monday\", \"Wednesday\", \"Friday\"],\n",
    "                        \"morning\":[4, 5, 6],\n",
    "                        \"afternoon\":[8, 9, 0]})\n",
    "example.set_index(\"day\", inplace=True)\n",
    "print(example)\n",
    "print(example.stack())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda3d487",
   "metadata": {},
   "source": [
    "## Example: Unstack\n",
    "* Conversely, for displaying data, it's often handy to have it in a wider format\n",
    "* Unstack is especially convenient after using `groupby` on a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ed45074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>program</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>44.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>26.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        score       value      \n",
       "program     x     y     x     y\n",
       "group                          \n",
       "a        44.0  71.0  14.5  15.0\n",
       "b        26.0  16.0  13.0  16.5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(100)\n",
    "long_data = pd.DataFrame({\"group\":[\"a\", \"a\", \"a\", \"a\", \"b\", \"b\", \"b\", \"b\"],\n",
    "                          \"program\":[\"x\", \"y\", \"x\", \"y\", \"x\", \"y\", \"x\", \"y\"],\n",
    "                         \"score\":rng.integers(0, 100, 8),\n",
    "                         \"value\":rng.integers(0, 20, 8)\n",
    "                         })\n",
    "long_data.groupby([\"group\", \"program\"]).mean()\n",
    "long_data.groupby([\"group\", \"program\"]).mean().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68556328",
   "metadata": {},
   "source": [
    "# Question 1: NHANES Table\n",
    "\n",
    "See Appendix for modified Q3 from Pset 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "058fb88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Part a: including gender\n",
    "data = pd.read_pickle(\"nhanes_demographic.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc50f460",
   "metadata": {},
   "source": [
    "For part b, I used this StackOverflow response to create a new variable\n",
    "https://stackoverflow.com/questions/48027171/create-a-variable-in-a-pandas-dataframe-based-on-information-in-the-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31697f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Part b: Merging ODESTS\n",
    "# Note that I renamed \"ODESTS\" to be \"dentition_status\" when I made the pickle\n",
    "teeth = pd.read_pickle(\"nhanes_teeth.pkl\")\n",
    "teeth[\"respondent_id\"] = teeth[\"respondent_id\"].astype(str)\n",
    "teeth_ds = teeth[[\"respondent_id\", \"dentition_status\"]]\n",
    "data2 = data.merge(teeth_ds, how = \"left\", on = \"respondent_id\")\n",
    "\n",
    "new_names = {\"respondent_id\":\"id\",\n",
    "             \"status\":\"exam_status\",\n",
    "            \"dentition_status\":\"ohx_status\"}\n",
    "data2.rename(columns=new_names, inplace=True)\n",
    "data2[\"under_20\"] = data2[\"age\"].copy().apply(lambda x: x < 20)\n",
    "\n",
    "def get_val(row):\n",
    "    college = ['Some college or AA degree', 'College graduate or above']\n",
    "    if row.educ_level == 'High school graduate / GED' or row.under_20:\n",
    "        return \"No college/<20\"\n",
    "    elif row.educ_level in college:\n",
    "        return \"some college/college graduate\"\n",
    "    else:\n",
    "        return np.nan\n",
    "data2[\"college\"] = data2.apply(get_val, axis = 1)\n",
    "\n",
    "data2 = data2[[\"id\", \"gender\", \"age\", \"under_20\", \n",
    "               \"college\", \"exam_status\", \"ohx_status\"]]\n",
    "\n",
    "def get_val_exam(row):\n",
    "    status = [\"Interviewed and examined\", \"Complete\"]\n",
    "    if row.exam_status == status[0] and row.ohx_status == status[1]:\n",
    "        return \"complete\"\n",
    "    else:\n",
    "        return \"missing\"\n",
    "data2[\"ohx\"] = data2.apply(get_val_exam, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb1b9471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1757 observations removed\n",
      "37399 observations remaining\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Part c: Removing where exam_status != \"Interviewed and examined\"\n",
    "data3 = data2.loc[data2[\"exam_status\"] == \"Interviewed and examined\", ].copy()\n",
    "print(str(data2.shape[0] - data3.shape[0]) + \" observations removed\")\n",
    "print(str(data3.shape[0]) + \" observations remaining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "766eb21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ohx</th>\n",
       "      <th>variable</th>\n",
       "      <th>complete</th>\n",
       "      <th>missing</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>Under 20?</td>\n",
       "      <td>20369.000000</td>\n",
       "      <td>1277.000000</td>\n",
       "      <td>1.922171e-259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>Under 20?</td>\n",
       "      <td>13991.000000</td>\n",
       "      <td>1762.000000</td>\n",
       "      <td>1.922171e-259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>Gender</td>\n",
       "      <td>17342.000000</td>\n",
       "      <td>1626.000000</td>\n",
       "      <td>8.048006e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>Gender</td>\n",
       "      <td>17018.000000</td>\n",
       "      <td>1413.000000</td>\n",
       "      <td>8.048006e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No college/&lt;20</th>\n",
       "      <td>Attended college?</td>\n",
       "      <td>18514.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>some college/college graduate</th>\n",
       "      <td>Attended college?</td>\n",
       "      <td>11386.000000</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>Age</td>\n",
       "      <td>33.169470</td>\n",
       "      <td>22.009543</td>\n",
       "      <td>1.770477e-126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>Age</td>\n",
       "      <td>24.367362</td>\n",
       "      <td>26.587235</td>\n",
       "      <td>1.770477e-126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Part d: Table with ohx and age, under_20, gender, college\n",
    "results_under_20 = data3.groupby([\"under_20\", \"ohx\"]).size().unstack()\n",
    "under_20_p = chisquare(results_under_20.values, axis=0).pvalue\n",
    "results_under_20[\"P-value\"] = under_20_p[0]\n",
    "results_gender = data3.groupby([\"gender\", \"ohx\"]).size().unstack()\n",
    "gender_p = chisquare(results_gender.values, axis=0).pvalue\n",
    "results_gender[\"P-value\"] = gender_p[0]\n",
    "results_college = data3.groupby([\"college\", \"ohx\"]).size().unstack()\n",
    "college_p = chisquare(results_college.values, axis=0).pvalue\n",
    "results_college[\"P-value\"] = college_p[0]\n",
    "results_age = data3.groupby([\"ohx\"]).age.agg([np.mean, np.std]).transpose()\n",
    "results_age[\"P-value\"] = 2*[ttest_ind(\n",
    "    data3.loc[data3[\"ohx\"]==\"complete\", \"age\"], \n",
    "    data3.loc[data3[\"ohx\"]==\"missing\", \"age\"])[1]]\n",
    "\n",
    "results_under_20[\"variable\"] = \"Under 20?\"\n",
    "results_gender[\"variable\"] = \"Gender\"\n",
    "results_college[\"variable\"] = \"Attended college?\"\n",
    "results_age[\"variable\"] = \"Age\"\n",
    "results = [results_under_20, results_gender, results_college, results_age]\n",
    "results = pd.concat(results)\n",
    "results = results[['variable','complete', 'missing', 'P-value']]\n",
    "results_display = pd.DataFrame(results)\n",
    "display(HTML(results_display.to_html(index=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b30d94",
   "metadata": {},
   "source": [
    "# Question 2: Monte Carlo Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e9b041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSet01 functions defined\n",
    "# -----------------------------------------------------------------------------\n",
    "methods = ['standard', 'clopper-pearson', 'jeffrey', 'agresti-coull']\n",
    "\n",
    "def get_ci_binomial(vector, method, level, output_format=\"pretty\"):\n",
    "    \"\"\"\n",
    "    Gives mean estimate and confidence interval using various methods.\n",
    "    Note that warning messages have been removed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vector : list or np.array\n",
    "        An object coercible to an np.array.\n",
    "    method : str\n",
    "        One of 'standard', 'clopper-pearson', 'jeffrey', 'agresti-coull'\n",
    "    level : float between 0 and 1\n",
    "        The confidence level (e.g. .95)\n",
    "    output_format : string or None\n",
    "        If output_format = None, unformatted dictionary is returned.\n",
    "        Otherwise formatted string is returned.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Point estimate with confidence interval in string or dictionary.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        np.array(vector)\n",
    "    except:\n",
    "        print(\"Input must be coercible to numpy array type\")\n",
    "    vector = np.array(vector)    \n",
    "    n = len(vector)\n",
    "    x = sum(vector)\n",
    "    p = x/n\n",
    "    alpha = 1 - level\n",
    "    z = norm.ppf(level + .5*alpha)\n",
    "    if method not in methods:\n",
    "        print(f\"Method must be one of {methods}\")\n",
    "    elif method == \"standard\":\n",
    "        # if p*n <= 12 or (1-p)*n <=12:\n",
    "            # print(\"You may not have sample size / balanced proportions.\")\n",
    "        se = (p*(1-p)/n)**(1/2)\n",
    "        lwr, upr = p - z*se, p + z*se    \n",
    "    elif method == \"clopper-pearson\":\n",
    "        lwr = beta.ppf(alpha/2, x, n-x+1)\n",
    "        upr = beta.ppf(1 - alpha/2, x+1, n-x)\n",
    "    elif method == \"jeffrey\":\n",
    "        lwr = max(0, beta.ppf(alpha/2, x+.5, n-x+.5))\n",
    "        upr = min(1, beta.ppf(1 - alpha/2, x+.5, n-x+.5))\n",
    "    elif method == \"agresti-coull\":\n",
    "        n_tilde = n + z**2\n",
    "        p_tilde = (x + ((z**2)/2))/n_tilde\n",
    "        se_tilde = (p_tilde*(1-p_tilde)/n_tilde)**(1/2)\n",
    "        lwr, upr = p_tilde - z*se_tilde, p_tilde + z*se_tilde\n",
    "        p = p_tilde\n",
    "    values = {\"est\":p, \"lwr\":lwr, \"upr\":upr, \"level\":level}\n",
    "    if output_format == None:\n",
    "        return(values)\n",
    "    else:\n",
    "        pr = round(p, 4)\n",
    "        lwrr = round(lwr, 4)\n",
    "        uprr = round(upr, 4)\n",
    "        return(f\"{pr} [{round(level*100)}% CI: ({lwrr}, {uprr})]\".format()) \n",
    "# -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ee662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Parts a and b: Calibration study\n",
    "# Let the confidence level of interest be .9\n",
    "\n",
    "p_vals = [round(.05*i, 2) for i in range(1, 10)]\n",
    "n_vals = [10**i for i in range(2, 5)]\n",
    "\n",
    "n_sims = 10000\n",
    "\n",
    "combs = list(product(p_vals, n_vals))\n",
    "combs = pd.DataFrame(combs, columns = [\"p\", \"n\"])\n",
    "\n",
    "widths = list(product(p_vals, n_vals))\n",
    "widths = pd.DataFrame(widths, columns = [\"p\", \"n\"])\n",
    "\n",
    "rng = np.random.default_rng(100)\n",
    "\n",
    "standard = []\n",
    "cp = []\n",
    "jeffrey = []\n",
    "ac = []\n",
    "\n",
    "sw = []\n",
    "cpw = []\n",
    "jw = []\n",
    "acw = []\n",
    "\n",
    "for i in range(len(combs.index)):\n",
    "    p = combs.iloc[i, ].loc[\"p\"].copy()\n",
    "    n = combs.iloc[i, ].loc[\"n\"].copy()\n",
    "    s = rng.binomial(n, p, n_sims)\n",
    "    contained = []\n",
    "    avg_width = []\n",
    "    for value in s:\n",
    "        binomial_list = [1]*value + [0]*round(n - value)\n",
    "        binomial_array = np.array(binomial_list)\n",
    "        intervals = []\n",
    "        this_width = []\n",
    "        for method in methods:\n",
    "            ci = get_ci_binomial(binomial_array, \n",
    "                                    method=method, \n",
    "                                    level=.9, \n",
    "                                    output_format=None)\n",
    "            intervals.append(ci[\"lwr\"] <= p <= ci[\"upr\"])\n",
    "            this_width.append(ci[\"upr\"] - ci[\"lwr\"])\n",
    "        contained.append(intervals)\n",
    "        avg_width.append(this_width)\n",
    "    means = pd.DataFrame(contained, columns = methods).mean()\n",
    "    standard.append(means[\"standard\"])\n",
    "    cp.append(means[\"clopper-pearson\"])\n",
    "    jeffrey.append(means['jeffrey'])\n",
    "    ac.append(means['agresti-coull'])\n",
    "    ci_widths = pd.DataFrame(avg_width, columns = methods).mean()\n",
    "    sw.append(ci_widths[\"standard\"])\n",
    "    cpw.append(ci_widths[\"clopper-pearson\"])\n",
    "    jw.append(ci_widths['jeffrey'])\n",
    "    acw.append(ci_widths['agresti-coull'])\n",
    "\n",
    "combs[\"standard\"] = standard\n",
    "combs[\"clopper-pearson\"] = cp\n",
    "combs[\"jeffrey\"] = jeffrey\n",
    "combs[\"agresti-coull\"] = ac\n",
    "\n",
    "widths[\"standard\"] = sw\n",
    "widths[\"clopper-pearson\"] = cpw\n",
    "widths[\"jeffrey\"] = jw\n",
    "widths[\"agresti-coull\"] = acw\n",
    "\n",
    "# combs.to_csv(\"combs.csv\")\n",
    "# widths.to_csv(\"widths.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a2c7a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0c0490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# part a: Actual coverage countour plot\n",
    "# Note: have to troubleshoot my matplotlib installation\n",
    "\n",
    "x = combs[\"n\"]\n",
    "y = combs[\"p\"]\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = combs[\"standard\"]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "CS = ax.contour(X, Y, Z, 20, cmap='RdGy')\n",
    "ax.clabel(CS, inline=True, fontsize=10)\n",
    "ax.set_title('Standard CI coverage rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7302d2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# part b: Width countour plot\n",
    "# Note: have to troubleshoot my matplotlib installation\n",
    "\n",
    "x = withds[\"n\"]\n",
    "y = widths[\"p\"]\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = widths[\"standard\"]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "CS = ax.contour(X, Y, Z, 20, cmap='RdGy')\n",
    "ax.clabel(CS, inline=True, fontsize=10)\n",
    "ax.set_title('Standard CI width')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294b038f",
   "metadata": {},
   "source": [
    "# Appendix: Modified Q3 from PSet 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a82e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Part a:\n",
    "\n",
    "# Set which vars and cohorts to extract\n",
    "relevant_vars = [\"SEQN\",\"RIAGENDR\", \"RIDAGEYR\", \"RIDRETH3\", \"DMDEDUC2\", \n",
    "                 \"DMDMARTL\", \"RIDSTATR\", \"SDMVPSU\", \"SDMVSTRA\", \n",
    "                 \"WTMEC2YR\", \"WTINT2YR\"]\n",
    "cohort_keys = [\"2011-2012/DEMO_G\", \"2013-2014/DEMO_H\", \n",
    "               \"2015-2016/DEMO_I\", \"2017-2018/DEMO_J\"]\n",
    "\n",
    "# Gather data from internet\n",
    "url_part_a = \"https://wwwn.cdc.gov/Nchs/Nhanes/\"\n",
    "url_part_c = \".XPT\"\n",
    "all_data = pd.DataFrame(columns=relevant_vars + [\"cohort\"])\n",
    "for years in cohort_keys:\n",
    "    url = url_part_a + years + url_part_c\n",
    "    df = pd.read_sas(url)\n",
    "    df = df.loc[:, relevant_vars]\n",
    "    df[\"cohort\"] = str(years)\n",
    "    all_data = pd.concat([all_data, df])\n",
    "    \n",
    "# Change names and types\n",
    "new_names = {\"SEQN\":\"respondent_id\",\n",
    "             \"RIAGENDR\":\"gender\",\n",
    "            \"RIDAGEYR\":\"age\",\n",
    "            \"RIDRETH3\":\"race\",\n",
    "            \"DMDEDUC2\":\"educ_level\",\n",
    "            \"DMDMARTL\":\"marital_status\",\n",
    "            \"RIDSTATR\":\"status\",\n",
    "            \"SDMVPSU\":\"psu\",\n",
    "            \"SDMVSTRA\":\"stratum\",\n",
    "            \"WTMEC2YR\":\"weight_exam\",\n",
    "            \"WTINT2YR\":\"weight_interview\"}\n",
    "new_types = {\"respondent_id\":str,\n",
    "            \"age\":int,\n",
    "            \"weight_exam\":float,\n",
    "            \"weight_interview\":float}\n",
    "all_data.rename(columns=new_names, inplace=True)\n",
    "all_data = all_data.astype(dtype=new_types)\n",
    "\n",
    "# Replace categorical data\n",
    "gender_dictionary = {1:\"Male\",\n",
    "                    2:\"Female\"}\n",
    "all_data['gender'] = pd.Categorical(all_data['gender'].replace(gender_dictionary))\n",
    "race_dictionary = {1: 'Mexican American', \n",
    "                   2: 'Other Hispanic',\n",
    "                   3: 'Non-Hispanic White',\n",
    "                   4: 'Non-Hispanic Black',\n",
    "                   6: 'Non-Hispanic Asian',\n",
    "                   7: 'Other Race / Multiracial'}\n",
    "all_data['race'] = pd.Categorical(all_data['race'].replace(race_dictionary))\n",
    "educ_dictionary = {1: 'Less than 9th grade',\n",
    "                  2: '9-11th grade',\n",
    "                  3: 'High school graduate / GED',\n",
    "                  4: 'Some college or AA degree',\n",
    "                  5: 'College graduate or above',\n",
    "                  7: 'Refused',\n",
    "                  9: 'Don\\'t know'}\n",
    "all_data['educ_level'] = pd.Categorical(\n",
    "    all_data['educ_level'].replace(educ_dictionary))\n",
    "marital_dictionary = {1: 'Married',\n",
    "                     2: 'Widowed',\n",
    "                     3: 'Divorced',\n",
    "                     4: 'Separated',\n",
    "                     5: 'Never married',\n",
    "                     6: 'Living with partner',\n",
    "                     77: 'Refused',\n",
    "                     99: 'Don\\'t Know'}\n",
    "all_data['marital_status'] = pd.Categorical(\n",
    "    all_data['marital_status'].replace(marital_dictionary))\n",
    "status_dictionary = {1: 'Interviewed only',\n",
    "                    2: 'Interviewed and examined'}\n",
    "all_data['status'] = pd.Categorical(\n",
    "    all_data['status'].replace(status_dictionary))\n",
    "\n",
    "# Write to pickle\n",
    "all_data.to_pickle(\"nhanes_demographic.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
